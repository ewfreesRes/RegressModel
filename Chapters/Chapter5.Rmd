
# Interpreting Regression Results

**Chapter description**

A case study, on determining an individual's characteristics that influence its health expenditures, illustrates the regression modeling process from start to finish. Subsequently, the chapter summarizes what we learn from the modeling process, underscoring the importance of variable selection.



```{r comment = "", eval = FALSE, echo = FALSE, warning = FALSE}
# Reformat Data Set
meps0 <- read.csv("CSVData\\HealthExpend.csv", header = TRUE)
str(meps0)
head(meps0)
meps <- subset(meps0, EXPENDOP>0)
# Change Variable Names to lower case
meps$expendop <- meps$EXPENDOP
meps$gender   <- meps$GENDER
meps$age      <- meps$AGE
meps$race     <- meps$RACE
meps$region   <- meps$REGION
meps$educ     <- meps$EDUC
meps$phstat   <- meps$PHSTAT
meps$mpoor    <- meps$MNHPOOR
meps$anylimit <- meps$ANYLIMIT
meps$income   <- meps$INCOME
meps$insure   <- meps$insure
meps$usc      <- meps$USC
meps$unemploy <- meps$UNEMPLOY
meps$managedcare <- meps$MANAGEDCARE
meps2 <- meps[c("expendop", "gender", "age", "race", "region", "educ", "phstat", "mpoor", "anylimit", "income", "insure", "usc", "unemploy", "managedcare")]
summary(meps2)
#write.csv(meps2,"CSVData\\HealthMeps.csv", row.names = FALSE)
```

## Case study: MEPS health expenditures


###Video 

<center>
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/1660902/sp/166090200/embedIframeJs/uiconf_id/25916071/partner_id/1660902?iframeembed=true&playerId=kaltura_player&entry_id=1_itjvn841&flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en&amp;flashvars[leadWithHTML5]=true&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;&wid=1_i3ynk1nx" width="649" height="401" allowfullscreen webkitallowfullscreen mozAllowFullScreen allow="autoplay *; fullscreen *; encrypted-media *" frameborder="0" title="Kaltura Player"></iframe>
</center>

#### Video Overhead Details {-}

<div class="tab">
  <button class="tablinks" onclick="openTab(event, 'Over5.1A')">A Details. MEPS health expenditures</button>
  <button class="tablinks" onclick="openTab(event, 'Over5.1B')">B Details. Overhead MEPS health expenditures</button>
  <button class="tablinks" onclick="openTab(event, 'Over5.1C')">C Details. Outcome variable</button>
  <button class="tablinks" onclick="openTab(event, 'Over5.1D')">D Details. Explanatory variables</button>
  <button class="tablinks" onclick="openTab(event, 'Over5.1E')">E Details. Case study outline</button>
</div>


<div id="Over5.1A" class="tabcontent">
  <span onclick="this.parentElement.style.display='none'" class="topright">Hide</span>
  <h3>A Details. MEPS health expenditures</h3>
  <p>

This exercise considers data from the *Medical Expenditure Panel Survey* (MEPS), conducted by the U.S. Agency of Health Research and Quality. MEPS is a probability survey that provides nationally representative estimates of health care use, expenditures, sources of payment, and insurance coverage for the U.S. civilian population. This survey collects detailed information on individuals of each medical care episode by type of services including physician office visits, hospital emergency room visits, hospital outpatient visits, hospital inpatient stays, all other medical provider visits, and use of prescribed medicines. This detailed information allows one to develop models of health care utilization to predict future expenditures. You can learn more about MEPS at http://www.meps.ahrq.gov/mepsweb/.

We consider MEPS data from the panels 7 and 8 of 2003 that consists of 18,735 individuals between ages 18 and 65. From this sample, we took a random sample of 2,000 individuals that appear in the file `HealthExpend`. From this sample, there are 1,352 that had positive outpatient expenditures. 

Our dependent variable is the amount of expenditures for outpatient visits, `expendop`. For MEPS, outpatient events include hospital outpatient department visits, office-based provider visits and emergency room visits excluding dental services. (Dental services, compared to other types of health care services, are more predictable and occur in a more regular basis.) Hospital stays with the same date of admission and discharge, known as "zero-night stays," were included in outpatient counts and expenditures. (Payments associated with emergency room visits that immediately preceded an inpatient stay were included in the inpatient expenditures. Prescribed medicines that can be linked to hospital admissions were included in inpatient expenditures, not in outpatient utilization.)

</p>
</div> 

<div id="Over5.1B" class="tabcontent">
  <span onclick="this.parentElement.style.display='none'" class="topright">Hide</span>
  <h3>B Details. Overhead MEPS health expenditures</h3>
  <p>

Data from the Medical Expenditure Panel Survey (MEPS), conducted by the U.S. Agency of Health Research and Quality (AHRQ).

- A probability survey that provides nationally representative estimates of health care use, expenditures, sources of payment, and insurance coverage for the U.S. civilian population.
- Collects detailed information on individuals of each medical care episode by type of services including
    - physician office visits,
    - hospital emergency room visits,
    - hospital outpatient visits,
    - hospital inpatient stays,
    - all other medical provider visits, and
    - use of prescribed medicines.
- This detailed information allows one to develop models of health care utilization to predict future expenditures.
- We consider MEPS data from the first panel of 2003 and take a random sample of *n* = 2, 000 individuals between ages 18 and 65.

</p>
</div> 

<div id="Over5.1C" class="tabcontent">
  <span onclick="this.parentElement.style.display='none'" class="topright">Hide</span>
  <h3>C Details. Outcome variable</h3>
  <p>

Our dependent variable is expenditures for outpatient admissions.

- For MEPS, inpatient admissions include persons who were admitted to a hospital and stayed overnight.
- In contrast, outpatient events include hospital outpatient department visits, office-based provider visits and emergency room visits excluding dental services.
    - Hospital stays with the same date of admission and discharge, known as "zero-night stays," were included in outpatient counts and expenditures.
    - Payments associated with emergency room visits that immediately preceded an inpatient stay were included in the inpatient expenditures.
    - Prescribed medicines that can be linked to hospital admissions were included in inpatient expenditures, not in outpatient utilization.

</p>
</div> 

<div id="Over5.1D" class="tabcontent">
  <span onclick="this.parentElement.style.display='none'" class="topright">Hide</span>
  <h3>D Details. Explanatory variables</h3>
  <p>

9 variables in the database. Here 13 most relevant.

$$
{\small \begin{array}{ll}
expendop    & \text{Amounts of expenditures for outpatient visits} \\
gender      & \text{Indicate gender of patient (=1 if female, =0 if male)} \\
age         & \text{Age in years between 18 and 65 }\\
race        & \text{Race of patient described as Asian, Black, Native, White and other} \\
region      & \text{Region of patient described as WEST, NORTHEAST, MIDWEST and SOUTH} \\
educ        & \text{Level of education received described by words (LHIGHSC, HIGHSCH and COLLEGE)} \\
phstat      & \text{Self-rated physical health status described as EXCE, VGOO, GOOD, FAIR and POOR} \\
mpoor       & \text{Self-rated mental health (=1 if poor or fair, =0 if good to excellent mental health)} \\
anylimit    & \text{Any activity limitation (=1 if any functional/activity limitation, =0 if otherwise)} \\
income      & \text{Income compared to poverty line described as POOR, NPOOR, LINCOME, MINCOME and HINCOME} \\
insure      & \text{Insurance coverage (=1 if covered by public/private health insurance in any month of 1996, =0 otherwise)} \\
usc         & \text{1 if dissatisfied with one's usual source of care} \\
unemploy    & \text{Employment status of patients} \\
managedcare & \text{1 if enrolled in an HMO or gatekeeper plan} \\
\end{array}}
$$

</p>
</div> 

<div id="Over5.1E" class="tabcontent">
  <span onclick="this.parentElement.style.display='none'" class="topright">Hide</span>
  <h3>E Details. Case study outline</h3>
  <p>

The next series of exercises leads you through an analysis of the steps for understanding a complex data set. Because of the complexity of the data, in each step only a sample of procedures will be executed.

The outline consists of:

- Summary statistics
- Splitting the data into training and testing portions with initial model fits
- Selecting variables to be included in the model

</p>
</div> 

###Exercise. Summarizing data

**Assignment Text**

With a complex dataset, you will probably want to take a look at the structure of the data. You are already familiar with taking a [summary()] of a dataframe which provides summary statistics for many variables. You will see that several variables in this dataframe are categorical, or factor, variables. We can use the  [table()](https://www.rdocumentation.org/packages/base/versions/3.5.0/topics/table) function to summarize them.

After getting a sense of the distributions of explanatory variables, we want to take a deeper dive into the distribution of the outcome variable, `expendop`. We will do this by comparing the histograms of the variable to that of its logarithmic version.

To examine relationships of the outcome variable visually, we look to scatterplots for continuous variables (such as `age`) and boxplots for categorical variables (such as `phstat`).


**Instructions**

- Examine the structure of the `meps` dataframe using the [str()](https://www.rdocumentation.org/packages/utils/versions/3.5.0/topics/str/) function. Also, get a [summary()] of the dataframe.
- Examine the distribution of the `race` variable using the [table()](https://www.rdocumentation.org/packages/base/versions/3.5.0/topics/table) function.
- Compare the expenditures distribution to its logarithmic version visually via histograms plotted next to another. `par(mfrow = c(1, 2))` is used to organize the plots you create.
- Examine the distribution of logarithmic expenditures in terms of levels of `phstat` visually using the 
[boxplot()](https://www.rdocumentation.org/packages/graphics/versions/3.5.0/topics/boxplot/) function.
- Examine the relationship of age versus logarithmic expenditures using a scatter plot. Superimpose a local fitting line using the [lines()](https://www.rdocumentation.org/packages/graphics/versions/3.5.0/topics/lines) and
[lowess()](https://www.rdocumentation.org/packages/stats/versions/3.5.0/topics/lowess) functions.

```{r ex="ExerRegMod5.1.2", type="hint", tut=TRUE}
One of the most important steps in linear regression is understanding your data. Using a combination of `str()` and  `summary()` lets you view quantitative statistics about your data, while `boxplot()` and `hist()` give you a more visual representation of your data.
```

```{r ex="ExerRegMod5.1.2", type="pre-exercise-code", tut=TRUE}
#meps <- read.csv("CSVData\\HealthMeps.csv", header = TRUE)
meps <- read.csv("https://assets.datacamp.com/production/repositories/2610/datasets/7b7dab6d0c528e4cd2f8d0e0fc7824a254429bf8/HealthMeps.csv", header = TRUE)
```

```{r ex="ExerRegMod5.1.2", type="sample-code", tut=TRUE}
# Examine the structure and get a summary of the `meps` dataframe 
str(___)
summary(___)

# Examine the distribution of the `race` variable 
table(___)

# Compare the expenditures distribution to its logarithmic version visually
par(mfrow = c(1, 2))
hist(___, main = "", xlab = "outpatient expenditures")
hist(log(___), main = "", xlab = "log expenditures")

# Examine the distribution of logarithmic expenditures in terms of levels of `phstat` 
par(mfrow = c(1, 1))
meps$logexpend <- log(meps$expendop)
boxplot(logexpend ~ ___, data = meps, main = "boxplot of log expend")

# Examine the relationship of age versus logarithmic expenditures. Superimpose a local fitting line.
plot(___,___, xlab = "age", ylab = "log expend")
lines(lowess(___, ___), col="red")

```


```{r ex="ExerRegMod5.1.2", type="solution", tut=TRUE}
str(meps)
summary(meps)
table(meps$race)
par(mfrow = c(1, 2))
hist(meps$expendop, main = "", xlab = "outpatient expenditures")
hist(log(meps$expendop), main = "", xlab = "log expenditures")
par(mfrow = c(1, 1))
meps$logexpend <- log(meps$expendop)
boxplot(logexpend ~ phstat, data = meps, main = "boxplot of log expend")
plot(meps$age,meps$logexpend, xlab = "age", ylab = "log expend")
lines(lowess(meps$age, meps$logexpend), col="red")

```


```{r ex="ExerRegMod5.1.2", type="sct", tut=TRUE}
ex() %>% check_function("str", not_called_msg="Use the `str` command to view the structure of the data. ") %>% check_arg(., "object") %>% check_equal(incorrect_msg="Make sure to specify that we would like the structure of the data `meps`.")
ex() %>% check_function("summary", not_called_msg="Use the `summary` function to view a summary of the data. ") %>% check_arg(., "object") %>% check_equal(incorrect_msg="Make sure to specify that we would like to view a summary of `meps`.")
ex() %>% check_function("table", not_called_msg="Use the `table` function to find the number of observations of each race. ") %>% check_result() %>% check_equal(incorrect_msg="Make sure to specify that we would like to create a table from `meps` that separates based on `race`.")
ex() %>% check_function("par",index=1,not_called_msg="Use the `par` function to alter the plotting device to have 2 side-by-side graphs. ") %>% check_arg(., "mfrow") %>% check_equal(incorrect_msg="To create two side-by-side graphs, set `mfrow` equal to `c(2,1)`. ")
ex() %>% check_function("hist",index=1, not_called_msg="Use the `hist` function to create a histogram of `expendop`.") %>% check_arg(., "x") %>% check_equal(incorrect_msg="Make sure to specify that we want the first histogram to be made using the data found in `expendop`, which is a column in `meps`.")
ex() %>% check_function("hist",index=2 not_called_msg="Use the `hist` function to create a histogram of the log of `expendop`.") %>% check_arg(., "x") %>% check_equal(incorrect_msg="Make sure to specify that we want the second histogram to be made using the log of the data found in `expendop`, which is a column in `meps`.")
ex() %>% check_function("par",index=2, not_called_msg="Use `par` to reset the plotting device to hold a single graph. ") %>% check_arg(., "mfrow") %>% check_equal(incorrect_msg="to reset the plotting device, set `mfrow` to be equal to `c(1,1). ")
ex() %>% check_object("meps") %>% check_column("logexpend", col_missing_msg="Make sure to create a new column in `meps` named `logexpend`.") %>% check_equal(incorrect_msg="The values in `logexpend` should be equal to the log of the values in `meps$expendop`.")
ex() %>% check_function("boxplot", not_called_msg="Use the `boxplot` function to create a boxplot showing `logexpend` based on `phstat`.") %>% {
  check_arg(., "formula") %>% check_equal(incorrect_msg="Make sure to specify that we want boxplots that show `logexpend` for each value of `phstat`.")
  check_arg(., "data") %>% check_equal(incorrect_msg="Make sure to specify that our data comes from the dataframe `meps`.")
}
ex() %>% check_function("plot", not_called_msg="Use `plot` to create a plot that shows `logexpend` based on `age`.") %>% {
  check_arg(., "x") %>% check_equal(incorrect_msg="The independent variable should be `age`.")
  check_arg(., "y") %>% check_equal(incorrect_msg="The dependent variable should be `logexpend`.")
}
ex() %>% check_function("lines", not_called_msg="Use the `lines` function to add a line to our plot. ") 
ex() %>% check_function("lowess", not_called_msg="Use the `lowess` function to add a smoothing effect to our line. ") %>% {
  check_arg(., "x") %>% check_equal(incorrect_msg="The first argument in `lowess` should be our `x` variable, which is `age`.")
  check_arg(., "y") %>% check_equal(incorrect_msg="The second argument in `lowess` should be our `y` variable, which is `logexpend`.")
}
success_msg("Excellent! Summarizing data, without reference to a model, is probably the most time-consuming part of any predictive modeling exercise. Summary statistics are also a key part of any report as they illustrate features of the data that are accessible to a broad audience.")

```

###Exercise. Fit a benchmark multiple linear regression model

**Assignment Text**

As part of the pre-processing for the model fitting, we will split the data into training and test subsamples. For this exercise, we use a 75/25 split although other choices are certainly suitable. Some analysts prefer to do this splitting before looking at the data. Another approach, adopted here, is that the final report typically contains summary statistcs of the entire data set and so it makes sense to do so when examining summary statistics.

We start by fitting a benchmark model. It is common to use all available explanatory variables with the outcome on the original scale and so we use this as our benchmark model. This exercise shows that when you [plot()](https://www.rdocumentation.org/packages/graphics/versions/3.5.0/topics/plot) a fitted linear regression model in `R`, the result provides four graphs that you have seen before. These can be useful for identifying an appropriate model.



**Instructions**

- Randomly split the data into a training and a testing data sets. Use 75\% for the training, 25\% for the testing.
- Fit a full model using `expendop` as the outcome and all explanatory variables. Summarize the results of this model fitting.
- You can [plot()](https://www.rdocumentation.org/packages/graphics/versions/3.5.0/topics/plot) the fitted model to view several diagnostic plots. These plots provide evidence that expenditures may not be the best scale for linear regression.
- Fit a full model using `logexpend` as the outcome and all explanatory variables and summarize the fit. Use the [plot()]() function for evidence that this variable is more suited for linear regression methods than expenditures on the original scale.

**Hint.** A `plot` of a regression object such as plot(mlr) provides four diagnostic plots. These can be organized as a 2 by 2 array using `par(mfrow = c(2, 2))`.

```{r ex="ExerRegMod5.1.3", type="hint", tut=TRUE}
A `plot` of a regression object such as plot(mlr) provides four diagnostic plots. These can be organized as a 2 by 2 array using `par(mfrow = c(2, 2))`.
```

```{r ex="ExerRegMod5.1.3", type="pre-exercise-code", tut=TRUE}
#meps <- read.csv("CSVData\\HealthMeps.csv", header = TRUE)
meps <- read.csv("https://assets.datacamp.com/production/repositories/2610/datasets/7b7dab6d0c528e4cd2f8d0e0fc7824a254429bf8/HealthMeps.csv", header = TRUE)
meps$logexpend <- log(meps$expendop)
```

```{r ex="ExerRegMod5.1.3", type="sample-code", tut=TRUE}
# Randomly split the data into a training and a testing data sets. Use 75\% for the training, 25\% for the testing.
n <- nrow(meps)
set.seed(12347)
shuffled_meps <- meps[sample(n), ]
train_indices <- 1:round(0.75 * n)
train_meps    <- shuffled_meps[train_indices, ]
test_indices  <- (round(0.25 * n) + 1):n
test_meps     <- shuffled_meps[test_indices, ]

# Fit a full model using `expendop` as the outcome and all explanatory variables. Summarize the results of this model fitting.
meps_mlr1 <- lm(___ ~ gender + age + race + region + educ + phstat + mpoor + anylimit + income + insure + usc + unemploy + managedcare, data = ___)
summary(meps_mlr1)

# Provide diagnostic plots of the fitted model. 
par(mfrow = c(2, 2))
plot(___)

# Fit a full model using `logexpend` as the outcome and all explanatory variables. Summarize the fit and examine diagnostic plots of the fitted model. 
meps_mlr2 <- lm(___ ~ gender + age + race + region + educ + phstat + mpoor + anylimit + income + insure + usc + unemploy + managedcare, data = ___)
summary(meps_mlr2)
plot(meps_mlr2)

```


```{r ex="ExerRegMod5.1.3", type="solution", tut=TRUE}
# Split the sample into a `training` and `test` data
n <- nrow(meps)
set.seed(12347)
shuffled_meps <- meps[sample(n), ]
train_indices <- 1:round(0.75 * n)
train_meps    <- shuffled_meps[train_indices, ]
test_indices  <- (round(0.25 * n) + 1):n
test_meps     <- shuffled_meps[test_indices, ]

meps_mlr1 <- lm(expendop ~ gender + age + race + region + educ + phstat + mpoor + anylimit + income + insure + usc + unemploy + managedcare, data = train_meps)
summary(meps_mlr1)
par(mfrow = c(2, 2))
plot(x=meps_mlr1)

meps_mlr2 <- lm(logexpend ~ gender + age + race + region + educ + phstat + mpoor + anylimit + income + insure + usc + unemploy + managedcare, data = train_meps)
summary(meps_mlr2)
plot(meps_mlr2)

```

```{r ex="ExerRegMod5.1.3", type="sct", tut=TRUE}
ex() %>% check_object("meps_mlr1", undefined_msg="Use `lm` to create a linear model named `meps_mlr1`".) %>% check_equal(incorrect_msg="Make sure to create this model so that `expendop` is based on `gender`, `age`, `race`, `region`, `educ`, `phstat`, `mpoor`, `anylimit`, `income`, `insure`, `usc`, `unemploy`, and `managedcare` from the dataframe `meps`.")
ex() %>% check_function("summary",index=1,not_called_msg="Use the `summary` function to view a summary of our linear model. ") %>% check_arg(., "object") %>% check_equal(incorrect_msg="Make sure to specify that we would like a summary of `meps_mlr1`.")
ex() %>% check_function("par", not_called_msg="Use the `par` function to alter the plotting device to show a 2 by 2 grid of graphs. ") %>% check_arg(., "mfrow") %>% check_equal(incorrect_msg="To create a 2 by 2 grid of graphs, set `mfrow` equal to `c(2,2)`. ")
ex() %>% check_function("plot",index=1, not_called_msg="Use `plot` to create the 4 plots associated with a linear model. ") %>% check_arg(., "x") %>% check_equal(incorrect_msg="If you set the parameter `x` to be equal to a linear model, in this case `meps_mlr1`, you will get 4 useful graphs!")
ex() %>% check_object("meps_mlr2", undefined_msg="Use `lm` to create a linear model named `meps_mlr2`.") %>% check_equal(incorrect_msg="Make sure to create this model so that `logexpend` is based on `gender`, `age`, `race`, `region`, `educ`, `phstat`, `mpoor`, `anylimit`, `income`, `insure`, `usc`, `unemploy`, and `managedcare` from the dataframe `meps`.")
ex() %>% check_function("summary",index=2, not_called_msg="Use the `summary` function to view a summary of our new linear model, `meps_mlr2`.") %>% check_arg(., "object") %>% check_equal(incorrect_msg="Make sure to specify that we would like a summary of `meps_mlr2`.")
ex() %>% check_function("plot",index=2, not_called_msg="Use the `plot` function to create the 4 plots associated with a linear model. ") %>% check_arg(., "x") %>% check_equal(incorrect_msg="If you set the parameter `x` to be equal to a linear model, in this case `meps_mlr2`, you will get 4 useful graphs!")
success_msg("Excellent! You may have compared the four diagnostic graphs from the MLR model fit of 'expend' to those created using the same procedure but with logarithmic expenditures as the outcome. This provides another piece of evidence that log expenditures are more suitable for regression modeling. Using logarithmic outcomes is a common feature of actuarial applications but can be difficult to diagnose and interpret without practice.")

```

###Exercise. Variable selection

**Assignment Text**

Modeling building can be approached using a "ground-up" strategy, where the analyst introduces a variable, examines residuls from a regression fit, and then seeks to understand the relationship between these residuals and other available variables so that these variables might be added to the model.

Another approach is a "top-down" strategy where all available variables are entered into a model and unnecessary variables are pruned from the model. Both approaches are helpful when using data to specify models. This exercise illustrates the latter approach, using the [step()] function to help narrow our search for the best fitting model.

**Instructions**

From our prior work, the training dataframe `train_meps` has already been loaded in. A multiple linear regression model fit object `meps_mlr2` is available that summarizes a fit of `logexpend` as the outcome variable using all 13 explanatory variables.

- Use the [step()](https://www.rdocumentation.org/packages/stats/versions/3.5.0/topics/step) function function to drop unnecessary variables from the full fitted model summarized in the object `meps_mlr2` and summarize this recommended model.
- As an alternative, use the explanatory variables in the recommended model and add the varibles `phstat`. Summarize the fit and note that statistical significance of the new variable.
- You have been reminded by your boss that use of the variable `gender` is unsuitable for actuarial pricing purposes. As an another alternative, drop `gender` from the recommended model (still keeping `phstat`). Note the statistical significance of the variable `usc`with this fitted model.

```{r ex="ExerRegMod5.1.4", type="hint", tut=TRUE}
Starting with a model that consists of all your explanatory variables and using `step()` is a good way to create a model that fits the data well. On the other hand, this is simply statistics, which is unable to capture "real" explanations, or follow regulatory rules.  
```

```{r ex="ExerRegMod5.1.4", type="pre-exercise-code", tut=TRUE}
#meps <- read.csv("CSVData\\HealthMeps.csv", header = TRUE)
meps <- read.csv("https://assets.datacamp.com/production/repositories/2610/datasets/7b7dab6d0c528e4cd2f8d0e0fc7824a254429bf8/HealthMeps.csv", header = TRUE)
meps$logexpend <- log(meps$expendop)
# Split the sample into a `training` and `test` data
n <- nrow(meps)
set.seed(12347)
shuffled_meps <- meps[sample(n), ]
train_indices <- 1:round(0.75 * n)
train_meps    <- shuffled_meps[train_indices, ]
test_indices  <- (round(0.25 * n) + 1):n
test_meps     <- shuffled_meps[test_indices, ]
```

```{r ex="ExerRegMod5.1.4", type="sample-code", tut=TRUE}
meps_mlr2 <- lm(logexpend ~ gender + age + race + region + educ + phstat + mpoor + anylimit + income + insure + usc + unemploy + managedcare, data = train_meps)
# Use the step() to drop unnecessary variables from the full fitted model summarized in the object `meps_mlr2` and summarize this recommended model.
model_stepwise <- step(meps_mlr2, data = ___, direction= "both", k = log(nrow(X)), trace = 0) 
summary(model_stepwise)

# As an alternative, use the explanatory variables in the recommended model and add the varibles `mpoor`. Summarize the fit  and note that statistical significance of the new variable.
meps_mlr4 <- lm(___ ~ gender + age + phstat + anylimit + insure  + ___, data = train_meps)
summary(meps_mlr4)

# You have been reminded by your boss that use of the variable `gender` is unsuitable for actuarial pricing purposes. As an another alternative, drop `gender` from the recommended model (still keeping `mpoor`). Note the statistical significance of the variable `usc`with this fitted model.
meps_mlr5 <- lm(logexpend ~ age + phstat + anylimit + insure  + ___, data = train_meps)
summary(___)

```

```{r ex="ExerRegMod5.1.4", type="solution", tut=TRUE}
meps_mlr2 <- lm(logexpend ~ gender + age + race + region + educ + phstat + mpoor + anylimit + income + insure + usc + unemploy + managedcare, data = train_meps)
#library(Rcmdr)
#temp <- stepwise(meps_mlr2, direction = 'backward/forward')
model_stepwise <- step(meps_mlr2, data = X, direction= "both", k = log(nrow(X)), trace = 0) 
summary(model_stepwise)
meps_mlr3 <- lm(logexpend ~ gender + age + phstat + anylimit + insure , data = train_meps)
summary(meps_mlr3)
meps_mlr4 <- lm(logexpend ~ gender + age + phstat + anylimit + insure  + mpoor, data = train_meps)
summary(meps_mlr4)
meps_mlr5 <- lm(logexpend ~ age + phstat + anylimit + insure  + mpoor, data = train_meps)
summary(meps_mlr5)

# par(mfrow = c(2, 2))
# plot(meps_mlr3)
# 
# meps_mlr4 <- lm(logexpend ~ gender + age + mpoor + anylimit + insure + usc  + phstat, data = train_meps)
# summary(meps_mlr4)
# 
# 
# meps_mlr5 <- lm(logexpend ~ age  + anylimit + mpoor + insure  + usc  + phstat, data = train_meps)
# summary(meps_mlr5)
# anova(meps_mlr4, meps_mlr5)
# 
# #boxplot(train_meps$logexpend ~ train_meps$phstat*train_meps$usc)

```

```{r ex="ExerRegMod5.1.4", type="sct", tut=TRUE}
ex() %>% check_object("meps_mlr2", undefined_msg="Use `lm` to create a linear model named `meps_mlr2`.") %>% check_equal(incorrect_msg="Make sure to create the linear model so that `logexpend` is based on `gender`, `age`, `race`, `region`, `educ`, `phstat`, `mpoor`, `anylimit`, `income`, `insure`, `usc`, `unemploy`, and `managedcare` from the data set `train_meps`.")
ex() %>% check_object("model_stepwise", undefined_msg="Utilize the `step` function to create a simplified model named `model_stepwise`.") %>% check_equal(incorrect_msg="Make sure to run `step` on `meps_mlr2` in both directions, and with k set to be the BIC estimate. ")
ex() %>% check_function("summary",index=1, not_called_msg="Use `summary` to create and view a summary of `model_stepwise`.") %>% check_arg(., "object") %>% check_equal(incorrect_msg="Make sure to specify that we would like a summary of `model_stepwise`.")
ex() %>% check_object("meps_mlr3", undefined_msg="Create a new linear model off a small number of explanatory variables named `meps_mlr3`.") %>% check_equal(incorrect_msg="When you create your linear model, make sure to model `logexpend` based on `gender`, `age`, `phstat`, `anylimit`, and `insure` from the dataframe `train_meps`.")
ex() %>% check_function("summary",index=2, not_called_msg="Use the `summary` function to create and view a summary of `meps_mlr3`.") %>% check_arg(., "object") %>% check_equal(incorrect_msg="Make sure to specify that we would like a summary of `meps_mlr3`.")
ex() %>% check_object("meps_mlr4", undefined_msg="Create a new linear model off a small number of explanatory variables named `meps_mlr4`.") %>% check_equal(incorrect_msg="When you create your linear model, make sure to model `logexpend` based on `gender`, `age`, `phstat`, `anylimit`, `insure`, and `mpoor` from the dataframe `train_meps`.")
ex() %>% check_function("summary",index=3, not_called_msg="Use the `summary` function to create and view a summary of `meps_mlr4`.") %>% check_arg(., "object") %>% check_equal(incorrect_msg="Make sure to specify that we would like a summary of `meps_mlr4`.")
ex() %>% check_object("meps_mlr5", undefined_msg="Create a new linear model off a small number of explanatory variables named `meps_mlr5`.") %>% check_equal(incorrect_msg="When you create your linear model, make sure to model `logexpend` based on `age`, `phstat`, `anylimit`, and `insure` from the dataframe `train_meps`.")
ex() %>% check_function("summary",index=4, not_called_msg="Use the `summary` function to create and view a summary of `meps_mlr5`.") %>% check_arg(., "object") %>% check_equal(incorrect_msg="Make sure to specify that we would like a summary of `meps_mlr5`.")
success_msg("Excellent! Sometimes variables may have good predictive power but are unacceptable for policy purposes - in insurance, ethnicity and sometimes sex are good examples. This implies that model interpretation can be just as important as the ability to predict.")

```

###Exercise. Model comparisons using cross-validation

**Assignment Text**

To compare alternative models, you decide to utilize cross-validation. For this exercise, you split the training sample into six subsamples of approximately equal size.

In the sample code, the cross-validation procedure has been summarized into a function that you can call. The input to the function is a list of variables that you select as your model explanatory variables. With this function, you can readily test several candidate models.

**Instructions**

- Run the cross validation (`crossvalfct`) function using the explanatory variables suggested by the stepwise function.
- Run the function again but adding the `mpoor` variable
- Run the function again but omitting the `gender` variable

Note which model is suggested by the cross validation function.

```{r ex="ExerRegMod5.1.5", type="hint", tut=TRUE}
Performing cross-validation measures on your model allows you to see how well it does when it comes to predicting "out of sample" data points.
```

```{r ex="ExerRegMod5.1.5", type="pre-exercise-code", tut=TRUE}
#meps <- read.csv("CSVData\\HealthMeps.csv", header = TRUE)
meps <- read.csv("https://assets.datacamp.com/production/repositories/2610/datasets/7b7dab6d0c528e4cd2f8d0e0fc7824a254429bf8/HealthMeps.csv", header = TRUE)
meps$logexpend <- log(meps$expendop)
# Split the sample into a `training` and `test` data
n <- nrow(meps)
set.seed(12347)
shuffled_meps <- meps[sample(n), ]
train_indices <- 1:round(0.75 * n)
train_meps    <- shuffled_meps[train_indices, ]
test_indices  <- (round(0.25 * n) + 1):n
test_meps     <- shuffled_meps[test_indices, ]

## Cross - Validation

crossvalfct <- function(explvars){
  cvdata   <- train_meps[, c("logexpend", explvars)]
  crossval <- 0
  for (i in 1:6) {
    indices <- (((i-1) * round((1/6)*nrow(cvdata))) + 1):((i*round((1/6) * nrow(cvdata))))
    # Exclude them from the train set
    train_mlr <- lm(logexpend ~ ., data = cvdata[-indices,])
    # Include them in the test set
    test  <- data.frame(cvdata[indices, explvars])
    names(test)  <- explvars
    predict_test <- exp(predict(train_mlr, test))
    # Compare predicted to held-out and summarize
    predict_err  <- exp(cvdata[indices, "logexpend"]) - predict_test
    crossval <- crossval + sum(abs(predict_err))
  }
  crossval/1000000
}
```

```{r ex="ExerRegMod5.1.5", type="sample-code", tut=TRUE}
# Run the cross validation (`crossvalfct`) function using the explanatory variables suggested by the stepwise function.
explvars.1 <- c("gender", "age", "phstat", "anylimit", "insure")
crossvalfct(explvars)

# Run the function again but adding the `mpoor` variable
explvars.2 <- c(___)
crossvalfct(explvars.2)

# Run the function again but omitting the `gender` variable
explvars.3 <- c( ___)
crossvalfct(explvars.3)

```


```{r ex="ExerRegMod5.1.5", type="solution", tut=TRUE}

explvars.1 <- c("gender", "age", "phstat", "anylimit", "insure")
crossvalfct(explvars.1)
explvars.2 <- c("gender", "age", "phstat", "anylimit", "insure", "mpoor")
crossvalfct(explvars.2)
explvars.3 <- c( "age", "phstat", "anylimit", "insure", "mpoor")
crossvalfct(explvars.3)
```


```{r ex="ExerRegMod5.1.5", type="sct", tut=TRUE}
ex() %>% check_object("explvars.1", undefined_msg="Create a variable named `explvars.1` that contains the following as character strings: `gender`, `age`, `phstat`, `anylimit`, and `insure`.") %>% check_equal(incorrect_msg="Make sure to specify that the following are expressed as character strings, and not as numbers: : `gender`, `age`, `phstat`, `anylimit`, and `insure`.")
ex() %>% check_function("crossvalfct",index=1, not_called_msg="Utilize the custom built function `crossvalfct` to find the cross-validation statistic for `explvars.1`.") %>% check_arg(., "explvars") %>% check_equal(incorrect_msg="Make sure to specify that we want the cross-validation statistic for `explvasr.1`.")
ex() %>% check_object("explvars.2", undefined_msg="Create a variable named `explvars.2` that contains the following as character strings: `gender`, `age`, `phstat`, `anylimit`, `insure`, and `mpoor`.") %>% check_equal(incorrect_msg="Make sure to specify that the following are expressed as character strings, and not as numbers: : `gender`, `age`, `phstat`, `anylimit`, `insure`, and `mpoor`.")
ex() %>% check_function("crossvalfct",index=2, not_called_msg="Utilize the custom built function `crossvalfct` to find the cross-validation statistic for `explvars.2`.") %>% check_arg(., "explvars") %>% check_equal(incorrect_msg="Make sure to specify that we want the cross-validation statistic for `explvasr.2`.")
ex() %>% check_object("explvars.3", undefined_msg="Create a variable named `explvars.3` that contains the following as character strings: `age`, `phstat`, `anylimit`, `insure`, and `mpoor`.") %>% check_equal(incorrect_msg="Make sure to specify that the following are expressed as character strings, and not as numbers: :`age`, `phstat`, `anylimit`, `insure`, and `mpoor`.")
ex() %>% check_function("crossvalfct",index=3, not_called_msg="Utilize the custom built function `crossvalfct` to find the cross-validation statistic for `explvars.3`.") %>% check_arg(., "explvars") %>% check_equal(incorrect_msg="Make sure to specify that we want the cross-validation statistic for `explvasr.3`.")
success_msg("Excellent! Cross-validation has become an essential piece of the data analysts toolkit. Good that you now have additional experience with it.")

```


###Exercise. Out of sample validation 

**Assignment Text**

From our prior work, the training `train_meps` and test `test_meps` dataframes have already been loaded in. We think our best model is based on logarithmic expenditures as the outcome and the following explanatory variables:

```
explvars3 <- c("gender", "age", "phstat", "anylimit", "insure", "mpoor")
```
We will compare this to a benchmark model that is based on expenditures as the outcome and all 13 explanatory variables

```
explvars4 <- c(explvars3, "race", "income", "region", "educ", "unemploy", "managedcare", "usc")
```

The comparisons will be based on expenditures in dollars using the held-out validation sample.

**Instructions**

- Use the training sample to fit a linear model with `logexpend` and explanatory variables listed in `explvars3`
- Predict expenditures (not logged) for the test data and summarize the fit using the sum of absolute prediction errors.
- Use the training sample to fit a benchmark linear model with `expendop` and explanatory variables listed in `explvars4`
- Predict expenditures for the test data and summarize the fit for the benchmark model using the sum of absolute prediction errors.
- Compare the predictions of the models graphically.

```{r ex="ExerRegMod5.1.6", type="hint", tut=TRUE}
There is nothing in this code to change. simply examine the code, play around with it, and figure out what each individual line does, and how they work together.
```

```{r ex="ExerRegMod5.1.6", type="pre-exercise-code", tut=TRUE}
#meps <- read.csv("CSVData\\HealthMeps.csv", header = TRUE)
meps <- read.csv("https://assets.datacamp.com/production/repositories/2610/datasets/7b7dab6d0c528e4cd2f8d0e0fc7824a254429bf8/HealthMeps.csv", header = TRUE)
meps$logexpend <- log(meps$expendop)
# Split the sample into a `training` and `test` data
n <- nrow(meps)
set.seed(12347)
shuffled_meps <- meps[sample(n), ]
train_indices <- 1:round(0.75 * n)
train_meps    <- shuffled_meps[train_indices, ]
test_indices  <- (round(0.25 * n) + 1):n
test_meps     <- shuffled_meps[test_indices, ]
explvars3 <- c("gender", "age", "race", "mpoor", "anylimit", "income", "insure", "usc")
explvars4 <- c(explvars3, "region", "educ", "phstat", "unemploy", "managedcare")
```


```{r ex="ExerRegMod5.1.6", type="sample-code", tut=TRUE}
# Regress `logexpend` on the explanatory variables listed in `explvars3`
meps_mlr3 <- lm(logexpend ~ gender + age + phstat + anylimit  + insure + mpoor, data = train_meps)

# Predict expenditures (not logged) and summarize using the sum of absolute prediction errors.
explvars3 <- c("gender", "age", "phstat", "anylimit", "insure", "mpoor")
predict_meps3 <- test_meps[,explvars3]
predict_mlr3  <- exp(predict(meps_mlr3, predict_meps3))
predict_err_mlr3 <- test_meps$expendop - predict_mlr3
sape3     <- sum(abs(predict_err_mlr3))/1000

# Regress `expendop` on all 13 explanatory variables
meps_mlr4 <- lm(___~ gender + age + race + region + educ + phstat + mpoor + anylimit + income + insure + usc + unemploy + managedcare, data = train_meps)

# Predict expenditures and summarize using the sum of absolute prediction errors.
explvars4 <- c("gender","age","race","region","educ","phstat","mpoor","anylimit","income","insure","usc","unemploy","managedcare")
predict_meps4 <- test_meps[,explvars4]
predict_mlr4  <- predict(meps_mlr4, predict_meps4)
predict_err_mlr4 <- test_meps$expendop - predict_mlr4
sape4     <- sum(abs(predict_err_mlr4))/1000
sape3;sape4

# Compare the predictions of the models graphically.
par(mfrow = c(1, 2))
plot(predict_err_mlr4, predict_err_mlr3, xlab = "Benchmark Predict Error", ylab = "MLR Predict Error")
plot(predict_mlr3, test_meps$expendop, xlab = "MLR Predicts", ylab = "Held Out Expends")

```


```{r ex="ExerRegMod5.1.6", type="solution", tut=TRUE}
meps_mlr3 <- lm(logexpend ~ gender + age + phstat + anylimit  + insure + mpoor, data = train_meps)
explvars3 <- c("gender", "age", "phstat", "anylimit", "insure", "mpoor")
predict_meps3 <- test_meps[,explvars3]
predict_mlr3  <- exp(predict(meps_mlr3, predict_meps3))
predict_err_mlr3 <- test_meps$expendop - predict_mlr3
sape3     <- sum(abs(predict_err_mlr3))/1000

meps_mlr4 <- lm(expendop ~ gender + age + race + region + educ + phstat + mpoor + anylimit + income + insure + usc + unemploy + managedcare, data = train_meps)
explvars4 <- c("gender","age","race","region","educ","phstat","mpoor","anylimit","income","insure","usc","unemploy","managedcare")
predict_meps4 <- test_meps[,explvars4]
predict_mlr4  <- predict(meps_mlr4, predict_meps4)
predict_err_mlr4 <- test_meps$expendop - predict_mlr4
sape4     <- sum(abs(predict_err_mlr4))/1000

sape3;sape4

par(mfrow = c(1, 2))
plot(predict_err_mlr4, predict_err_mlr3, xlab = "Benchmark Predict Error", ylab = "MLR Predict Error")
plot(predict_mlr3, test_meps$expendop, xlab = "MLR Predicts", ylab = "Held Out Expends")


```



```{r ex="ExerRegMod5.1.6", type="sct", tut=TRUE}
ex() %>% check_object("meps_mlr3", undefined_msg="Use `lm` to create a linear model named `meps_mlr3`.") %>% check_equal(incorrect_msg="Make sure to create your model so that `logexpend` is based on `gender`, `age`, `phstat`, `anylimit`, `insure`, and `mpoor` from the data in `train_meps`.")
ex() %>% check_object("explvars3", undefined_msg="Create a variable named `explvars3` that has `gender`, `age`, `phstat`, `anylimit`, `insure`, and `mpoor` as character strings. ") %>% check_equal(incorrect_msg="Make sure to have the following as a character string instead of the values contained in each: `gender`, `age`, `phstat`, `anylimit`, `insure`, and `mpoor`.")
ex() %>% check_object("predict_meps3", undefined_msg="Make a new dataframe named `predict_meps3` that a subset of the data not used to create the model. ") %>% check_equal(incorrect_msg="The subset of data not used is stored in `test_meps`, and the columns we want are now stored in `explvars3`.")
ex() %>% check_function("exp",index=1,not_called_msg="Make sure to take the exponential of the predicted values to remove the log effect. ") %>% check_arg(., "x") %>% check_equal(incorrect_msg="Make sure to run `exp` on the values you get from your `predict` call. ")
ex() %>% check_function("predict",index=1, not_called_msg="Run `predict` on the data you did not use to create the model. ") %>% {
  check_arg(., "object") %>% check_equal(incorrect_msg="Make sure to specify that the model we are using to make predictions is `meps_mlr3`.")
  check_arg(., "newdata") %>% check_equal(incorrect_msg="Make sure to specify that we would like predictions for the values found in `predict_meps3`.")
}
ex() %>% check_object("predict_mlr3", undefined_msg="Make sure to save the exponential of the predicted values to `predict_mlr3`.") %>% check_equal(incorrect_msg="Make sure to take the exponential of the values found using `predict`.")
ex() %>% check_object("predict_err_mlr3", undefined_msg="Save the prediction errors to a variable named `predict_err_mlr3`) %>% check_equal(incorrect_msg="To find the prediction errors, subtract the predicted values in `predict_mlr3` from the actual values found in `test_meps$expendop`.")
ex() %>% check_function("abs",index=1, undefined_msg="Make sure to take the absolute value of the prediction errors. ") %>% check_arg(., "x") %>% check_equal(incorrect_msg="Make sure to take the absolute value of the prediction errors, which can be found in `predict_err_mlr3`.")
ex() %>% check_function("sum",index=1, not_called_msg="Take the sum of the absolute value of the prediction errors. ") %>% check_arg(., "x") %>% check_equal(incorrect_msg="Make sure to specify that we would like the sum of the absolute value of the prediction errors. ")
ex() %>% check_object("sape3", undefined_msg="Make sure to set the sum of the absolute value of the prediction errors divided by 1000 equal to `sape3`.") %>% check_equal(incorrect_msg="Make sure that you have taken the sum of the absolute value of the prediction errors, and divided that number by 1000. ")
ex() %>% check_object("meps_mlr4", undefined_msg="Use `lm` to create a linear model named `meps_mlr4`.") %>% check_equal(incorrect_msg="Make sure to create your model so that `expendop` is based on `gender`,` age`, `race`, `region`, `educ`, `phstat`, `mpoor`, `anylimit`, `income`, `usc`, `unemploy`, and `managedcare` from the data in `train_meps`.")
ex() %>% check_object("explvars4", undefined_msg="Create a variable named `explvars4` that has `gender`,` age`, `race`, `region`, `educ`, `phstat`, `mpoor`, `anylimit`, `income`, `usc`, `unemploy`, and `managedcare` as character strings. ") %>% check_equal(incorrect_msg="Make sure to have the following as a character string instead of the values contained in each: `gender`,` age`, `race`, `region`, `educ`, `phstat`, `mpoor`, `anylimit`, `income`, `usc`, `unemploy`, and `managedcare`.")
ex() %>% check_object("predict_meps4", undefined_msg="Make a new dataframe named `predict_meps4` that a subset of the data not used to create the model. ") %>% check_equal(incorrect_msg="The subset of data not used is stored in `test_meps`, and the columns we want are now stored in `explvars4`.")
ex() %>% check_function("exp",index=2,not_called_msg="Make sure to take the exponential of the predicted values to remove the log effect. ") %>% check_arg(., "x") %>% check_equal(incorrect_msg="Make sure to run `exp` on the values you get from your `predict` call. ")
ex() %>% check_function("predict",index=2, not_called_msg="Run `predict` on the data you did not use to create the model. ") %>% {
  check_arg(., "object") %>% check_equal(incorrect_msg="Make sure to specify that the model we are using to make predictions is `meps_mlr4`.")
  check_arg(., "newdata") %>% check_equal(incorrect_msg="Make sure to specify that we would like predictions for the values found in `predict_meps4`.")
}
ex() %>% check_object("predict_mlr4", undefined_msg="Make sure to save the exponential of the predicted values to `predict_mlr4`.") %>% check_equal(incorrect_msg="Make sure to take the exponential of the values found using `predict`.")
ex() %>% check_object("predict_err_mlr4", undefined_msg="Save the prediction errors to a variable named `predict_err_mlr4`) %>% check_equal(incorrect_msg="To find the prediction errors, subtract the predicted values in `predict_mlr4` from the actual values found in `test_meps$expendop`.")
ex() %>% check_function("abs",index=2, undefined_msg="Make sure to take the absolute value of the prediction errors. ") %>% check_arg(., "x") %>% check_equal(incorrect_msg="Make sure to take the absolute value of the prediction errors, which can be found in `predict_err_mlr4`.")
ex() %>% check_function("sum",index=2, not_called_msg="Take the sum of the absolute value of the prediction errors. ") %>% check_arg(., "x") %>% check_equal(incorrect_msg="Make sure to specify that we would like the sum of the absolute value of the prediction errors. ")
ex() %>% check_object("sape4", undefined_msg="Make sure to set the sum of the absolute value of the prediction errors divided by 1000 equal to `sape4`.") %>% check_equal(incorrect_msg="Make sure that you have taken the sum of the absolute value of the prediction errors, and divided that number by 1000. ")
ex() %>% check_function("par",not_called_msg="Use `par` to alter the graphing device to have 2 side by side graphs. ") %>% check_arg(., "mfrow") %>% check_equal(incorrect_msg="To do this, set `mfrow` equal to `c(2,1)`. ")
ex() %>% check_function("plot",index=1, not_called_msg="Create a plot of the two prediction errors as the first graph. ") %>% {
  check_arg(., "x") %>% check_equal(incorrect_msg="The x axis should have the prediction errors from `predict_err_mlr4`.")
  check_arg(., "y") %>% check_equal(incorrect_msg="The y axis should have the prediction errors from `predict_err_mlr3`.")
}
ex() %>% check_function("plot",index=2, not_called_msg="The second graph should plot the predictions from mlr3 against the actual values of expenditures. ") %>% {
  check_arg(., "x") %>% check_equal(incorrect_msg="The X axis should have the predictions, found in `predict_mlr3`.")
  check_arg(., "y") %>% check_equal(incorrect_msg="The Y axis should have the actual expenditure values, found in `test_meps$expendop`.")
}
success_msg("Excellent! We found that the model of log expenditures outperforms the benchmark that models expenditures, even when the out of sample criterion was in the original 'dollar' units. It is comoforting to know that a search for a good model does well when using different out of sample criteria.")

```

```{r comment = "", warning = FALSE, message = FALSE, eval = FALSE, echo = FALSE}
explvars <- c("gender")
cvdata   <- train_meps[, c("logexpend", explvars)]
train_mlr <- lm(logexpend ~ ., data = cvdata[-indices,])
temp <- data.frame(cvdata[indices, explvars])
str(temp)
names(temp) <- explvars
str(temp)
predict_testa  <- exp(predict(train_mlr, temp))

predict_testa  <- exp(predict(train_mlr, gender=temp))
sum(predict_testa)
predict_testb  <- exp(predict(train_mlr, explvars=data.frame(cvdata[indices, explvars])))
sum(predict_testb)
predict_testc  <- exp(predict(train_mlr, explvars=cvdata[indices, explvars]))
sum(predict_testc)
```



## What the modeling procedure tells us

***

In this section, you learn how to:
  
- Interpret individual effects, based on their substantive and statistical significance
- Describe other purposes of regression modeling, including regression function for pricing, benchmarking studies, and predicting future observations.

***

###Video 

<center>
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/1660902/sp/166090200/embedIframeJs/uiconf_id/25916071/partner_id/1660902?iframeembed=true&playerId=kaltura_player&entry_id=1_j3k2286f&flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en&amp;flashvars[leadWithHTML5]=true&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;&wid=1_zdgkxkik" width="649" height="401" allowfullscreen webkitallowfullscreen mozAllowFullScreen allow="autoplay *; fullscreen *; encrypted-media *" frameborder="0" title="Kaltura Player"></iframe>
</center>

#### Video Overhead Details {-}

<div class="tab">
  <button class="tablinks" onclick="openTab(event, 'Over5.2A')">A Details. Interpreting individual effects</button>
  <button class="tablinks" onclick="openTab(event, 'Over5.2B')">B Details. Other Interpretations</button>
</div>


<div id="Over5.2A" class="tabcontent">
  <span onclick="this.parentElement.style.display='none'" class="topright">Hide</span>
  <h3>A Details. Interpreting individual effects</h3>
  <p>

- Substantive Effect
    - Does a 1 unit change in $x$ imply an economically meaningful change in $y$?
    - Example: Looking at urban and rural claims experience, is there a big enough difference to warrant differentiating prices by location? 
- Statistical Significance
    - We have standards for deciding whether or not a variable is statistically significant.
    - A "statistically significant effect" is the result of a  regression coefficient that is large relative to its standard error.
- Statistical significance is driven by
    - precision of $s$,
    - collinearity ($VIF$) and
    - sample size
- **Causal Effects**
    - If we change $x$, would $y$ change?

</p>
</div> 

<div id="Over5.2B" class="tabcontent">
  <span onclick="this.parentElement.style.display='none'" class="topright">Hide</span>
  <h3>B Details. Other Interpretations</h3>
  <p>

- Regression function and pricing
    - The regression function is $\mathrm{E~}y = \beta_0 + \beta_1 x_1 + \cdots +\beta _k x_k$.
    - Think about expected claims as our baseline price for short-term insurance coverages.
- Benchmarking studies
    - In studies of CEO's salaries, who is making a lot (or a little), controlled for industry, years of experience and so forth?
    - In studies of medical claims, who are the high-cost patients?
- Prediction
    - A new patient comes in with a given set of characteristics, what can I say about his or her future medical claims?

</p>
</div> 

<br>
    
<a style="color:blue">**MC Exercise. Which of the following are not important when interpreting the effects of individual variables?**</a>
<form >
<input type="radio" name="choice" value="Incorrect"> Substantive significance<br>
<input type="radio" name="choice" value="Incorrect"> Statistical significance<br>
<input type="radio" name="choice" value="Correct"> The amount of effort that it took to gather the data and do the analysis<br>
<input type="radio" name="choice" value="Incorrect"> Role of causality <br>
</form>
<button onclick="submitAnswer()">Submit Answer</button>
<br><br>

<a style="color:blue">**MC Exercise. Which of the following is not a potential explanation for the lack of statistical significance of an explanatory variable?**</a>
<form >
<input type="radio" name="choice" value="Incorrect"> Large variation of the disturbance term<br>
<input type="radio" name="choice" value="Incorrect"> High collinearity, so that the variable may be confounded with other variables<br>
<input type="radio" name="choice" value="Correct"> The coefficient of determination, $R^2$, is not sufficiently large<br>
</form>
<button onclick="submitAnswer()">Submit Answer</button>
<br><br>

<a style="color:blue">**MC Exercise. Which of the following is not an important purpose of regression modeling?**</a>
<form >
<input type="radio" name="choice" value="Incorrect"> Pricing of risks such as insurance contracts<br>
<input type="radio" name="choice" value="Incorrect"> Benchmarking studies, to compare an observation to others<br>
<input type="radio" name="choice" value="Incorrect"> Prediction<br>
<input type="radio" name="choice" value="Correct"> Keeping a computer occupied with work<br>
</form>
<button onclick="submitAnswer()">Submit Answer</button>




## The importance of variable selection

***

In this section, you learn how to:
  
- Describe the bias that can occur when omitting important variables
- Describe the principle of parsimony and reasons for adopting this approach

***

###Video 

<center>
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/1660902/sp/166090200/embedIframeJs/uiconf_id/25916071/partner_id/1660902?iframeembed=true&playerId=kaltura_player&entry_id=1_g3ysmpxy&flashvars[streamerType]=auto&amp;flashvars[localizationCode]=en&amp;flashvars[leadWithHTML5]=true&amp;flashvars[sideBarContainer.plugin]=true&amp;flashvars[sideBarContainer.position]=left&amp;flashvars[sideBarContainer.clickToClose]=true&amp;flashvars[chapters.plugin]=true&amp;flashvars[chapters.layout]=vertical&amp;flashvars[chapters.thumbnailRotator]=false&amp;flashvars[streamSelector.plugin]=true&amp;flashvars[EmbedPlayer.SpinnerTarget]=videoHolder&amp;flashvars[dualScreen.plugin]=true&amp;&wid=1_qjxtcbse" width="649" height="401" allowfullscreen webkitallowfullscreen mozAllowFullScreen allow="autoplay *; fullscreen *; encrypted-media *" frameborder="0" title="Kaltura Player"></iframe>
</center>

#### Video Overhead Details {-}

<div class="tab">
  <button class="tablinks" onclick="openTab(event, 'Over5.3A')">A Details. The importance of variable selection</button>
  <button class="tablinks" onclick="openTab(event, 'Over5.3B')">B Details. Example. Regression using one explanatory variable</button>
  <button class="tablinks" onclick="openTab(event, 'Over5.3C')"C Details. Principle of parsimony</button>
</div>


<div id="Over5.3A" class="tabcontent">
  <span onclick="this.parentElement.style.display='none'" class="topright">Hide</span>
  <h3>A Details. The importance of variable selection</h3>
  <p>

- With too many or too few variables, $s$ is too large an estimate of $\sigma$.
    - Prediction intervals are too large
    - Standard errors for the partial slopes are too large
- With too few or incorrect variables, we produce biased estimates of the slopes $\beta$. Thus, our predictions are biased and hence inaccurate.

</p>
</div> 

<div id="Over5.3B" class="tabcontent">
  <span onclick="this.parentElement.style.display='none'" class="topright">Hide</span>
  <h3>B Details. Example. Regression using one explanatory variable</h3>
  <p>

- **Too Many Variables**
    - The "true" model is $y_i = \beta_0+ \varepsilon_i$
    - We mistakenly use $y_i = \beta_0+ \beta_1 x_i^* + \varepsilon_i$
    - The prediction at a generic level $x$ is $b_0^* + b_1^* x$.
    - It is not to hard to confirm that $Bias   =   \mathrm{E} (b_0^* + b_1^* x) - \mathrm{E } y= 0$.
- **Too Few Variables**
    - The "true" model is   $y_i = \beta_0 + \beta_1 x_i + \varepsilon_i$.
    - We mistakenly use  $y_i = \beta_0^* \varepsilon_i$.
    - Under the true model,  $\overline{y} = \beta_0 + \beta_1 \overline{x} + \overline{\varepsilon}$
    - Thus, the bias is

$$
Bias  = \text{E }\bar{y} - \text{E }(\beta_0 + \beta_1 x + \varepsilon) \\
= \text{E }(\beta_0 + \beta_1 \bar{x}+\bar{\varepsilon})-(\beta_0+\beta_1 x)=\beta_1 (\bar{x}-x).
$$


There is a persistent, long-term error in omitting the explanatory variable $x$.

</p>
</div> 

<div id="Over5.3C" class="tabcontent">
  <span onclick="this.parentElement.style.display='none'" class="topright">Hide</span>
  <h3>C Details. Principle of parsimony</h3>
  <p>

- The principle of parsimony, also known as *Occam's Razor*, states that when there are several possible explanations for a phenomenon, use the simplest.
    - A simpler explanation is easier to interpret.
    - Simpler models, also known as ``more parsimonious'' models, often do well on fitting out-of-sample data
    - Extraneous variables can cause problems of collinearity, leading to difficulty in interpreting individual coefficients.
- In contrast, in a quote often attributed to Albert Einstein, we should use "the simplest model possible, but no simpler."
    - Omitting important variables can lead to biased results, a potentially serious error.
    - Including extraneous variables decreases the degrees of freedom and increases the estimate of variability, typically of less concern in actuarial applications.

</p>
</div>     
    
<br>
<a style="color:blue">**MC Exercise. Which of the following is true about under- and over-fitting a model?**</a>
<form >
<input type="radio" name="choice" value="Incorrect">  When we over-fit a model, estimates of regression coefficients are over-biased as is $s^2$, the estimate of model variance $\sigma^2$.<br>
<input type="radio" name="choice" value="Correct"> When we over-fit a model, estimates of regression coefficients remain unbiased whereas $s^2$, the estimate of model variance  $\sigma^2$, is over-biased.<br>
<input type="radio" name="choice" value="Incorrect"> When we over-fit a model, estimates of regression coefficients remain under-biased as is $s^2$, the estimate of model variance  $\sigma^2$.<br>
<input type="radio" name="choice" value="Incorrect"> When we under-fit a model, estimates of regression coefficients remain unbiased whereas $s^2$, the estimate of model variance  $\sigma^2$, is over-biased.<br>
</form>
<button onclick="submitAnswer()">Submit Answer</button>
<br><br>

<a style="color:blue">**MC Exercise. Which of the following is not true of Occam's Razor?**</a>
<form >
<input type="radio" name="choice" value="Incorrect"> When there are several possible explanations for a phenomenon, use the simplest one.<br>
<input type="radio" name="choice" value="Incorrect"> Simpler models are easier to interpret.<br>
<input type="radio" name="choice" value="Correct"> Variables can be statistically significant but practically unimportant.<br>
<input type="radio" name="choice" value="Incorrect"> Simpler models often do better for predicting out-of-sample data<br>
</form>
<button onclick="submitAnswer()">Submit Answer</button>
 

<!-- **Overhead D. Course wrap up** -->

<!-- Thanks for watching -->


```{r comment = "", eval = FALSE, echo = FALSE}

## Risk Manager's Analysis
survey <- read.table("CSVData\\RiskSurvey.csv", header = TRUE, sep = ",")
str(survey)
attach(survey)

lmsurvey <- lm(FIRMCOST ~ ASSUME + CAP + SIZELOG + INDCOST + SOPH + CENTRAL,
   data = survey)
summary(lmsurvey)

#  hist(lmsurvey$residuals)
survey$rstudent.lmsurvey <- rstudent(lmsurvey)
survey$hatvalues.lmsurvey <- hatvalues(lmsurvey)

#  FIGURE  6.5
par(mfrow = c(1, 2))
library(Rcmdr)
Hist(survey$rstudent.lmsurvey, scale = "frequency", breaks = 16)
Hist(survey$hatvalues.lmsurvey, scale = "frequency", breaks = 16)


#  TABLE 6.3 SUMMARY STATS
library(abind)
numSummary(survey[,c("ASSUME", "CAP", "CENTRAL", "FIRMCOST", "INDCOST", "SIZELOG", "SOPH")], 
  statistics = c("mean", "sd", "quantiles"), quantiles = c(0,.5,1))

#  TABLE 6.4 MEANS BY LEVEL OF CAP
survey$COSTLOG <- with(survey, log(FIRMCOST))
survey$CAPfactor <- as.factor(survey$CAP)

numSummary(survey[,c("ASSUME", "CAP", "CENTRAL", "COSTLOG", "FIRMCOST", "INDCOST", "SIZELOG", "SOPH")], 
  groups = survey$CAPfactor, statistics = c("mean", "sd", "quantiles"), quantiles = c(0,.5,1))

#  TABLE 6.5 CORRELATIONS
cor(survey[,c("ASSUME","CAP","CENTRAL","COSTLOG","FIRMCOST","INDCOST", "SIZELOG","SOPH")], use = "complete.obs")

#  FIGURE  6.6
layout(matrix(c(1,2,3,4,5,6,7,8,9,10,11,12),byrow = TRUE,ncol = 6))
par("oma" = c(3,3,3,3),"mai" = c(0,0,0.1,0))

plot.new()
Hist(survey$ASSUME,scale = "frequency",breaks = 18,main = "ASSUME", xaxt = "n", yaxt = "n")
Hist(survey$SIZELOG,scale = "frequency",breaks = 18,main = "SIZELOG", xaxt = "n", yaxt = "n")
Hist(survey$INDCOST,scale = "frequency",breaks = 18,main = "INDCOST", xaxt = "n", yaxt = "n")
Hist(survey$CENTRAL,scale = "frequency",breaks = 18,main = "CENTRAL", xaxt = "n", yaxt = "n")
Hist(survey$SOPH,scale = "frequency",breaks = 18,main = "SOPH", xaxt = "n", yaxt = "n")
Hist(survey$FIRMCOST,scale = "frequency",breaks = 18,main = "FIRMCOST", xaxt = "n", yaxt = "n")

plot(ASSUME,FIRMCOST, xaxt = "n", yaxt = "n")
plot(SIZELOG,FIRMCOST, xaxt = "n", yaxt = "n")
plot(INDCOST,FIRMCOST, xaxt = "n", yaxt = "n")
plot(CENTRAL,FIRMCOST, xaxt = "n", yaxt = "n")
plot(SOPH,FIRMCOST, xaxt = "n", yaxt = "n")

#  FIGURE  6.7
Hist(survey$COSTLOG, scale = "frequency", breaks = 16)

#  FIGURE  6.8
layout(matrix(c(1,2,3,4,5),byrow = TRUE,ncol = 5))
par("oma" = c(3,5,3,3),"mai" = c(0,0,0.2,0))
plot(ASSUME,survey$COSTLOG,main = "ASSUME",xaxt = "n",yaxt = "n",ylab = "COSTLOG")
plot(SIZELOG,survey$COSTLOG,main = "SIZELOG",xaxt = "n",yaxt = "n")
plot(INDCOST,survey$COSTLOG,main = "INDCOST",xaxt = "n",yaxt = "n")
plot(CENTRAL,survey$COSTLOG,main = "CENTRAL",xaxt = "n",yaxt = "n")
plot(SOPH,survey$COSTLOG,main = "SOPH",xaxt = "n",yaxt = "n")
dev.off()

lm2survey <- lm(COSTLOG~ASSUME+CAP+SIZELOG+INDCOST+CENTRAL+SOPH,
  data = survey)
summary(lm2survey)
#hist(lm2survey$residuals)
survey$rstudent.lm2survey <- rstudent(lm2survey)
survey$hatvalues.lm2survey <- hatvalues(lm2survey)

#  FIGURE  6.9
par(mfrow = c(1, 2))
Hist(survey$rstudent.lm2survey, scale = "frequency", breaks = 16)
Hist(survey$hatvalues.lm2survey, scale = "frequency", breaks = 16)


#  VARIANCE INFLATION FACTORS NOT A PROBLEM
#  library(faraway)
#  The "vif" function is also under the library "faraway" if you haven't opened up the Rcmdr library. 

vif(lm2survey)

# STEPWISE REGRESSION SUGGESTS SIZELOG AND INDCOST
stepwise(lm2survey, direction = 'backward/forward', criterion = 'AIC')

# The "stepwise" function is in the Rcmdr library, alternatively, you can use the following codes:
# step(im2survey)

lm3survey <- lm(COSTLOG~SIZELOG+INDCOST,data = survey)
summary(lm3survey)
#hist(lm3survey$residuals)
survey$rstudent.lm3survey <- rstudent(lm3survey)
survey$hatvalues.lm3survey <- hatvalues(lm3survey)

#  FIGURE  6.10
par(mfrow = c(1, 2))
Hist(survey$rstudent.lm3survey, scale = "frequency", breaks = 16)
Hist(survey$hatvalues.lm3survey, scale = "frequency", breaks = 16)


#  FIGURE  6.11 
survey$residuals.lm3survey <- residuals(lm3survey)
plot(INDCOST,survey$residuals.lm3survey,xlab = "INDCOST",ylab = "RESIDUAL")
survey$INDCOST2 <- with(survey, INDCOST*INDCOST)

lm4survey <- lm(survey$residuals.lm3survey~INDCOST+INDCOST2,data = survey)
summary(lm4survey)

lm5survey <- lm(COSTLOG~SIZELOG+INDCOST+INDCOST2,data = survey)
summary(lm5survey)

#quadfit <- lm4survey$coefficients[1] + lm4survey$coefficients[2]*INDCOST #+lm4survey$coefficients[3]*INDCOST2
plot(INDCOST,survey$residuals.lm3survey,xlab = "INDCOST",ylab = "RESIDUAL")
lines(lowess(INDCOST,survey$residuals.lm3survey, f = .8))

```
